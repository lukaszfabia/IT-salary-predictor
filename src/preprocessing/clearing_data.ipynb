{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapis i naprawa danych z formatu JSON do CSV.\n",
    "\n",
    "Na początku tworze sobie synonimy dla najpopularniejszych nazw miast, ponieważ w niektórych przypadkach, \n",
    "miasta mają w sobie literówki np. `Waraszawa` albo nie obsłużyłem wystarczająco dużo przypadków przy miastach.\n",
    "Następnie naprawiamy sobie lokacje oraz technologie. W przypadku technologii nie naprawam ich ponieważ mam pewność że są poprawne przez to ze były w jednym miejscu na stronie oraz po przejrzeniu ich nie znalazłem błędów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "# import pandas as pd\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "locations_synonyms: Dict[str, List[str]] = {\n",
    "    \"Warszawa\": [\"Warsaw\", \"Warszawa\", \"Katowice; Warszawa\", \"Warszawa (Centrum)\", \"Waraszawa\"],\n",
    "    \"Kraków\": [\"Krakow\", \"Kraków\"],\n",
    "    \"Wrocław\": [\"Wroclaw\", \"Wrocław\"],\n",
    "    \"Poznań\": [\"Poznan\", \"Poznań\", \"Pozanań\"],\n",
    "    \"Gdańsk\": [\"Gdansk\", \"Gdańsk\"],\n",
    "    \"Szczecin\": [\"Szczecin, szczecin\"],\n",
    "    \"Łódź\": [\"Lodz\", \"Łódź\"],\n",
    "    \"Rzeszów\": [\"Rzeszow\", \"Rzeszów\"],\n",
    "    \"Katowice\": [\"Katowice\", \"Katowice; Warszawa\"],\n",
    "    \"Kielce\": [\"Kielce\"],\n",
    "    \"Opole\": [\"opole\", \"Opole\"],\n",
    "    \"Sopot\": [\"Sopot\"],\n",
    "    \"Olszytn\": [\"Olsztyn\"],\n",
    "}\n",
    "    \n",
    "\n",
    "# def normalize_locations(locations: List[str]) -> List[str]:\n",
    "#     \"\"\"fix your locations\n",
    "\n",
    "#     Args:\n",
    "#         locations (List[str]): list from your data \n",
    "\n",
    "#     Returns:\n",
    "#         List[str]: list with appeared locations\n",
    "#     \"\"\"\n",
    "#     normalized_locations: List[str] = list()\n",
    "#     for tech in locations:\n",
    "#         for key, values in locations_synonyms.items():\n",
    "#             if tech in values:\n",
    "#                 normalized_locations.append(key)\n",
    "                \n",
    "#     return normalized_locations\n",
    "\n",
    "# # read data from json file and evaluate it to list\n",
    "# with open(\"../../data/offers.json\", \"r\") as file:\n",
    "#     jobs_list = eval(file.read())\n",
    "\n",
    "# df = pd.DataFrame(jobs_list)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# df[\"experience_code\"] = label_encoder.fit_transform(df[\"experience\"])\n",
    "# df[\"operating_mode_code\"] = label_encoder.fit_transform(df[\"operating_mode\"])\n",
    "\n",
    "# df[\"locations\"] = df[\"locations\"].apply(normalize_locations)\n",
    "\n",
    "# mlb_tech = MultiLabelBinarizer()\n",
    "# technologies_encoded = mlb_tech.fit_transform(df[\"technologies\"])\n",
    "\n",
    "# mlb_loc = MultiLabelBinarizer()\n",
    "# locations_encoded = mlb_loc.fit_transform(df[\"locations\"])\n",
    "\n",
    "# df_encoded = df.join(pd.DataFrame(technologies_encoded, columns=mlb_tech.classes_))\n",
    "\n",
    "# df_encoded = df_encoded.join(pd.DataFrame(locations_encoded, columns=mlb_loc.classes_))\n",
    "\n",
    "# df_encoded = df_encoded.drop(columns=[\"technologies\", \"locations\"])\n",
    "\n",
    "# df_encoded.to_csv(\"../../data/jobs_with_encoded_technologies_and_locations.csv\", index=False)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "# read data from json file\n",
    "df = pd.read_json(\"../../data/offers.json\")\n",
    "\n",
    "def normalize_location(location):\n",
    "    for key, values in locations_synonyms.items():\n",
    "        if location in values:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "# normalizacja lokalizacji\n",
    "df[\"locations\"] = df[\"locations\"].apply(lambda x: [normalize_location(loc) for loc in x])\n",
    "\n",
    "# lista wszystkich lokalizacji\n",
    "all_locations = list(set([loc for sublist in df[\"locations\"].tolist() for loc in sublist]))\n",
    "\n",
    "# utwórz LabelEncoder dla lokalizacji\n",
    "location_encoder = LabelEncoder()\n",
    "location_encoder.fit(all_locations)\n",
    "\n",
    "# zakoduj lokalizacje dla każdej oferty pracy\n",
    "df[\"location_code\"] = df[\"locations\"].apply(lambda x: [location_encoder.transform([loc])[0] for loc in x])\n",
    "\n",
    "# utwórz nowe wiersze dla każdej lokalizacji\n",
    "new_rows = []\n",
    "for index, row in df.iterrows():\n",
    "    for loc_code in row[\"location_code\"]:\n",
    "        new_row = row.copy()\n",
    "        new_row[\"location_code\"] = loc_code\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# utwórz nowy dataframe z nowymi wierszami\n",
    "df_new = pd.DataFrame(new_rows)\n",
    "\n",
    "# usuń kolumny 'locations' z wieloma lokalizacjami\n",
    "df_new = df_new.drop(columns=[\"locations\"])\n",
    "\n",
    "# kodowanie LabelEncoder dla innych kategorii\n",
    "label_encoder = LabelEncoder()\n",
    "df_new[\"experience_code\"] = label_encoder.fit_transform(df_new[\"experience\"])\n",
    "df_new[\"operating_mode_code\"] = label_encoder.fit_transform(df_new[\"operating_mode\"])\n",
    "\n",
    "# kodowanie MultiLabelBinarizer dla technologii\n",
    "mlb_tech = MultiLabelBinarizer()\n",
    "technologies_encoded = mlb_tech.fit_transform(df_new[\"technologies\"])\n",
    "\n",
    "# dołączanie zakodowanych technologii do dataframe\n",
    "df_encoded = df_new.join(pd.DataFrame(technologies_encoded, columns=mlb_tech.classes_))\n",
    "\n",
    "df_encoded = df_encoded.drop(columns=[\"technologies\"])\n",
    "\n",
    "# zapisz do pliku CSV\n",
    "df_encoded.to_csv(\"../../data/jobs_with_encoded_technologies_and_single_location.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usuwanie niepotrzebnych danych\n",
    "\n",
    "Na wszelki wypadek usuwam niepotrzebne dane, które mogą być niepotrzebne w przyszłości.\n",
    "<p style=\"color: red\">W przypadku ofert pracy gdzie nie ma definiowanych widełek dla np. b2b nie będę ich próbował wyliczać, bo nie ma to sensu, ponieważ zarobki zależą od technologi i poziomu doświadczenia.</p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "offers = pd.read_csv(\"../../data/jobs_with_encoded_technologies_and_single_location.csv\")\n",
    "\n",
    "offers = offers.drop_duplicates()\n",
    "offers = offers.dropna()\n",
    "\n",
    "offers[\"min_b2b\"] = offers[\"min_b2b\"].apply(lambda x: x * 20 * 8 if x < 700 else x)\n",
    "offers[\"max_b2b\"] = offers[\"max_b2b\"].apply(lambda x: x * 20 * 8 if x < 1000 else x)\n",
    "\n",
    "offers.columns = offers.columns.str.strip()\n",
    "\n",
    "offers.to_csv(\"../../data/jobs1.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie tego etapu\n",
    "\n",
    "Na tym etapie mamy już czyste dane, które możemy zacząć analizować. Dokonałem normalizacji lokalizacji oraz upewniłem się, że nie ma duplikatów w ofertach albo wartości NaN (not a number). Następnie konwerujemy pensje \n",
    "go godzinowe na miesięczne oraz usuwamy spacje w kolumnach.\n",
    "\n",
    "Można się jeszcze zastanowić nad tym czy warto podzielić dane na 3 kategorie, które dotyczą widełek (zawiera widełki):\n",
    "- B2B \n",
    "- UOP\n",
    "- Oba "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
